{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp_mean\n",
    "дефолтные параметры + условная оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import rpy2.robjects as robjects\n",
    "# from rpy2.robjects import pandas2rai\n",
    "# pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "container = np.load('shorten_year_data_2000.npz')\n",
    "dfq = [container[key] for key in container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # read data from RDS format\n",
    "# readRDS = robjects.r['readRDS']\n",
    "# dfq = readRDS('shorten_deseasonalized_quarter_data')\n",
    "# dfq = pandas2ri.ri2py(dfq)\n",
    "\n",
    "# dfm = readRDS('shorten_deseasonalized_month_data')\n",
    "# dfm = pandas2ri.ri2py(dfm)\n",
    "\n",
    "# # добавить еще новый dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "horq = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VSModel():\n",
    "    '''\n",
    "    Victoria's model\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, theta_1=0.1, theta_2=2.1, alpha=0.5, beta=0.2, phi=0.1, method='exp_mean', use_h = False, lr = 0.001, \n",
    "                 schedule = None, schedule_factor=0.9, verbose=5, is_sgd=True):\n",
    "        '''\n",
    "        theta_1 - theta of the 1st line, usually 0 < theta_1 < 1\n",
    "        theta_2 - theta of the 2nd line, usually > 1\n",
    "        alpha - coefficient for exponential mean\n",
    "        method - method to extrapolate z's values, possible values: exp_mean, exp_trend, holts, damped\n",
    "        h - use h for predicting or not (not for exp_mean)\n",
    "        lr - learning rate\n",
    "        schedule - function for schedule of the probability to add true next value or predicted value\n",
    "        schedule_factor - parameter for the schedule\n",
    "        verbose - frequency for verbose output\n",
    "        sgd - if True - use stochastic gradient descent, else - compute full loss and then make gd step\n",
    "        '''\n",
    "        self.is_sgd = is_sgd\n",
    "        \n",
    "        self.logs = dict()\n",
    "        self.logs['err_log'] = []\n",
    "        self.logs['mean_err_log'] = []\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.test_size = None\n",
    "        \n",
    "        self.theta_1 = Variable(torch.FloatTensor(np.array([theta_1])), requires_grad=True)\n",
    "        self.theta_2 = Variable(torch.FloatTensor(np.array([theta_2])), requires_grad=True)\n",
    "        self.logs['theta_1'] = [theta_1]\n",
    "        self.logs['theta_2'] = [theta_2]\n",
    "        \n",
    "        self.using_method = method\n",
    "        self.use_h = use_h\n",
    "        \n",
    "        self.b_cur = None\n",
    "        self.l_cur = None\n",
    "        \n",
    "        if schedule is None:\n",
    "            self.schedule = self.exp_schedule\n",
    "        else:\n",
    "            self.schedule = schedule\n",
    "        self.schedule_factor = schedule_factor\n",
    "        \n",
    "        if method == 'exp_mean':\n",
    "            self.method = self.exp_mean\n",
    "            self.method_next = self.exp_mean_next\n",
    "            \n",
    "            self.alpha = Variable(torch.FloatTensor(np.array([alpha])), requires_grad=True)\n",
    "            self.logs['alpha'] = [alpha]\n",
    "            \n",
    "        elif method == 'exp_trend':\n",
    "            self.method = self.exp_trend\n",
    "            self.method_next = self.exp_trend_next\n",
    "            \n",
    "            self.alpha = Variable(torch.FloatTensor(np.array([alpha])), requires_grad=True)\n",
    "            self.beta = Variable(torch.FloatTensor(np.array([beta])), requires_grad=True)\n",
    "            self.logs['alpha'] = [alpha]\n",
    "            self.logs['beta'] = [beta]\n",
    "            \n",
    "        elif method == 'holts':\n",
    "            self.method = self.holts\n",
    "            self.method_next = self.holts_next\n",
    "            \n",
    "            self.alpha = Variable(torch.FloatTensor(np.array([alpha])), requires_grad=True)\n",
    "            self.beta = Variable(torch.FloatTensor(np.array([beta])), requires_grad=True)\n",
    "            self.logs['alpha'] = [alpha]\n",
    "            self.logs['beta'] = [beta]\n",
    "            \n",
    "        elif method == 'damped':\n",
    "            self.method = self.damped\n",
    "            self.method_next = self.damped_next\n",
    "            \n",
    "            self.alpha = Variable(torch.FloatTensor(np.array([alpha])), requires_grad=True)\n",
    "            self.beta = Variable(torch.FloatTensor(np.array([beta])), requires_grad=True)\n",
    "            self.phi = Variable(torch.FloatTensor(np.array([phi])), requires_grad=True)\n",
    "            self.logs['alpha'] = [alpha]\n",
    "            self.logs['beta'] = [beta]\n",
    "            self.logs['phi'] = [phi]\n",
    "            \n",
    "        else:\n",
    "            print(':P')\n",
    "            print('Wrong method')\n",
    "        \n",
    "    def exp_schedule(self, cur_prob, iteration):\n",
    "        '''Schedule for the probabilty, exponential decay'''\n",
    "        return cur_prob * self.schedule_factor\n",
    "        \n",
    "    def exp_mean(self, z):\n",
    "        '''Compute exponential mean with coefficient alpha'''\n",
    "        \n",
    "        exp = Variable(torch.arange(z.shape[0] - 1, -1, -1))\n",
    "        power = torch.pow(1 - self.alpha, exp)\n",
    "        \n",
    "        return torch.sum(self.alpha * power * z)\n",
    "    \n",
    "    def exp_mean_next(self, prev_z, next_z):\n",
    "        return self.alpha * next_z + (1 - self.alpha) * prev_z\n",
    "\n",
    "    def exp_trend(self, z):\n",
    "        self.l_cur = z[0]\n",
    "        self.b_cur = z[1] / z[0]\n",
    "        cur_val = None\n",
    "        \n",
    "#         print(self.l_cur, self.b_cur)\n",
    "        for i in range(len(z)):\n",
    "            cur_val = self.exp_trend_next(z[i])\n",
    "        \n",
    "        return cur_val\n",
    "        \n",
    "    def exp_trend_next(self, prev_z, next_z = None, l=None, b=None, h = 1):\n",
    "        if l is None:\n",
    "            l = self.l_cur\n",
    "        if b is None:\n",
    "            b = self.b_cur\n",
    "#         print(l, 'b')\n",
    "        self.b_cur = self.beta * (self.alpha * prev_z + (1 - self.alpha) * l * b) / l + (1 - self.beta) * b\n",
    "        self.l_cur = self.alpha * prev_z + (1 - self.alpha) * l * b\n",
    "\n",
    "        return self.l_cur * torch.pow(self.b_cur, h)\n",
    "        \n",
    "    def holts(self, z):\n",
    "        self.l_cur = z[0]\n",
    "        self.b_cur = z[1] - z[0]\n",
    "        cur_val = None\n",
    "        \n",
    "        for i in range(len(z)):\n",
    "            cur_val = self.holts_next(z[i])\n",
    "        \n",
    "        return cur_val\n",
    "        \n",
    "    def holts_next(self, prev_z, next_z = None, l=None, b=None, h = 1):\n",
    "        if l is None:\n",
    "            l = self.l_cur\n",
    "        if b is None:\n",
    "            b = self.b_cur\n",
    "\n",
    "        self.b_cur = self.beta * ((self.alpha * prev_z + (1 - self.alpha) * (l + b)) - l) + (1 - self.beta) * b\n",
    "        self.l_cur = self.alpha * prev_z + (1 - self.alpha) * (l + b)\n",
    "\n",
    "        return self.l_cur + self.b_cur * h\n",
    "\n",
    "    def damped(self, z):\n",
    "        self.l_cur = z[0]\n",
    "        self.b_cur = z[1] - z[0]\n",
    "        cur_val = None\n",
    "        \n",
    "        for i in range(len(z)):\n",
    "            cur_val = self.damped_next(z[i])\n",
    "        \n",
    "        return cur_val\n",
    "        \n",
    "    def damped_next(self, prev_z, next_z = None, l=None, b=None, h = 1):\n",
    "        if l is None:\n",
    "            l = self.l_cur\n",
    "        if b is None:\n",
    "            b = self.b_cur\n",
    "\n",
    "        self.b_cur = (self.beta * ((self.alpha * prev_z + (1 - self.alpha) * (l + self.phi * b)) - l) +\n",
    "                     (1 - self.beta) * self.phi * b)\n",
    "        \n",
    "        self.l_cur = self.alpha * prev_z + (1 - self.alpha) * (l + self.phi * b)\n",
    "\n",
    "        return self.l_cur + torch.cumsum(torch.pow(self.phi, h), -1) * self.b_cur\n",
    "        \n",
    "    def get_predict(self, em1, em2):\n",
    "        '''Compute predicted value, formulas required, that 0 < theta_1 < 1, theta_2 > 1'''\n",
    "        \n",
    "        w1 = (self.theta_2 - 1) / (self.theta_2 - self.theta_1)\n",
    "        w2 = (1 - self.theta_1) / (self.theta_2 - self.theta_1)\n",
    "        \n",
    "        return w1 * em1 + w2 * em2\n",
    "    \n",
    "    def mae(self, target, predict):\n",
    "        '''Compute mean average error'''\n",
    "        \n",
    "#         print(predict)\n",
    "        idx = torch.LongTensor(np.array(np.isnan(predict.data.numpy()), dtype=int))\n",
    "        return torch.mean(torch.abs(predict[idx] - target[idx]))\n",
    "    \n",
    "    def logging(self):\n",
    "        self.logs['theta_1'].append(self.theta_1.data.numpy()[0])\n",
    "        self.logs['theta_2'].append(self.theta_2.data.numpy()[0])\n",
    "        \n",
    "        if 'alpha' in self.logs:\n",
    "            self.logs['alpha'].append(self.alpha.data.numpy()[0])\n",
    "        if 'beta' in self.logs:\n",
    "            self.logs['beta'].append(self.beta.data.numpy()[0])\n",
    "        if 'phi' in self.logs:\n",
    "            self.logs['phi'].append(self.phi.data.numpy()[0])\n",
    "            \n",
    "    def print_graph(self):\n",
    "        clear_output()\n",
    "        plt.plot(np.arange(len(self.logs['theta_1'])), self.logs['theta_1'], label='theta_1')\n",
    "        plt.plot(np.arange(len(self.logs['theta_2'])), self.logs['theta_2'], label='theta_2')\n",
    "        plt.title('Current values: theta_1 = {}, theta_2 = {}'.format(self.theta_1.data.numpy()[0], self.theta_2.data.numpy()[0]))\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        \n",
    "        for name in ['alpha', 'beta', 'phi']:\n",
    "            if name in self.logs:\n",
    "                plt.plot(np.arange(len(self.logs[name])), self.logs[name], label=name)\n",
    "                plt.title('Current value {} = {}'.format(name, self.logs[name][-1]))\n",
    "                plt.legend(loc='best')\n",
    "                plt.show()\n",
    "                \n",
    "        plt.plot(np.arange(len(self.logs['err_log'])), self.logs['err_log'], label='err_log', alpha=0.3)\n",
    "        plt.plot(np.arange(len(self.logs['mean_err_log'])) * self.test_size, self.logs['mean_err_log'], label='mean_err_log', alpha=0.7)\n",
    "        plt.title('Current values: err_log = {}, mean_err_log = {}'.format(self.logs['err_log'][-1], self.logs['mean_err_log'][-1]))\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        \n",
    "    def fit(self, data_base, data_train, n_iters, optimizer=torch.optim.Adam, loss_function=None, \n",
    "            constraints_1=True, constraints_2=True, lr=None):\n",
    "        '''\n",
    "        Find optimal theta_1, theta_2 and alpha with gradiend descent\n",
    "        \n",
    "        data_base - data to compute first n thetas\n",
    "        data_train - data to optimize parameters with GD\n",
    "        n_iters - number of epochs\n",
    "        optimizer - which type of GD to use\n",
    "        loss_function - function to compute error, should be writtein on pytorch, syntax: loss_function(target, predict),\n",
    "        default value is mae\n",
    "        constraints_1 - flag to constraint values of thetas\n",
    "        constraints_2 - flag to constraint values of alpha, beta, phi\n",
    "        '''\n",
    "        \n",
    "        if loss_function is None:\n",
    "            loss_function = self.mae\n",
    "        \n",
    "        if lr is None:\n",
    "            lr = self.lr\n",
    "        \n",
    "        #Simple preparing\n",
    "        y_np = np.copy(data_base)\n",
    "        n = len(y_np)\n",
    "        \n",
    "        t_np = np.arange(n) + 1\n",
    "        t_var = Variable(torch.FloatTensor(t_np))\n",
    "        y_var = Variable(torch.FloatTensor(y_np))\n",
    "        \n",
    "        #Compute coefficients A and B from the article\n",
    "        B = 6 / (n ** 2 - 1) * (2 / n * np.sum(t_np * y_np) - (1 + n) / n * np.sum(y_np))\n",
    "        A = 1 / n * np.sum(y_np) - (n + 1) / 2 * B\n",
    "        \n",
    "        B = Variable(torch.FloatTensor(np.array([B])))\n",
    "        A = Variable(torch.FloatTensor(np.array([A])))\n",
    "        \n",
    "        #Compute sequence of z_t from the article\n",
    "        z_var_1 = self.theta_1 * y_var + (1 - self.theta_1) * (A + B * t_var)\n",
    "        z_var_2 = self.theta_2 * y_var + (1 - self.theta_2) * (A + B * t_var)\n",
    "#         next_z1 = self.theta_1 * targets_var[i] + (1 - self.theta_1) * (A + B * (n + i))\n",
    "#         next_z2 = self.theta_2 * targets_var[i] + (1 - self.theta_2) * (A + B * (n + i))\n",
    "\n",
    "        list_of_params = [self.theta_1, self.theta_2, self.alpha]\n",
    "        if self.using_method in ['exp_trend', 'holts', 'damped']:\n",
    "            list_of_params.append(self.beta)\n",
    "        if self.using_method == 'damped':\n",
    "            list_of_params.append(self.phi)\n",
    "            \n",
    "        opt = optimizer(list_of_params, lr=lr)\n",
    "        targets_np = np.copy(data_train)\n",
    "        targets_var = Variable(torch.FloatTensor(targets_np))\n",
    "        \n",
    "        prob = 1\n",
    "        self.test_size = targets_var.shape[0]\n",
    "        \n",
    "#         for it in tqdm(range(n_iters)):\n",
    "        for it in range(n_iters):\n",
    "#             print(self.l_cur, self.b_cur, 'a')\n",
    "            if not self.is_sgd:\n",
    "                full_predict = Variable(torch.FloatTensor(np.zeros(self.test_size)))\n",
    "    \n",
    "            if self.using_method == 'exp_mean' or not self.use_h:\n",
    "                # Compute exponential mean to predict\n",
    "                z1_predict = self.method(z_var_1)\n",
    "                z2_predict = self.method(z_var_2)\n",
    "                \n",
    "                for i in range(targets_var.shape[0]):\n",
    "                    #predict\n",
    "                    predict = self.get_predict(z1_predict, z2_predict)\n",
    "#                     print(predict)\n",
    "                    #Gradient step\n",
    "                    if self.is_sgd:\n",
    "                        opt.zero_grad()\n",
    "                        loss = loss_function(predict, targets_var[i])\n",
    "                        self.logs['err_log'].append(loss.data.numpy()[0])\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        opt.step()\n",
    "                    else:\n",
    "                        full_predict[i] = predict\n",
    "\n",
    "                    #Limiting values\n",
    "                    if constraints_1:\n",
    "                        if (self.theta_1 < 0).data.numpy():\n",
    "                            self.theta_1 = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "                        if (self.theta_1 > 1).data.numpy():\n",
    "                            self.theta_1 = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "                        if (self.theta_2 < 1).data.numpy():\n",
    "                            self.theta_2 = Variable(torch.FloatTensor(np.array([1.5])), requires_grad=True)\n",
    "                    \n",
    "                    if constraints_2:    \n",
    "                        if (self.alpha > 1).data.numpy():\n",
    "                            self.alpha = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "                        if (self.alpha < 0).data.numpy():\n",
    "                            self.alpha = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "\n",
    "                        if 'beta' in self.logs and (self.beta > 1).data.numpy():\n",
    "                            self.beta = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "                        if 'beta' in self.logs and (self.beta < 0).data.numpy():\n",
    "                            self.beta = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "\n",
    "                        if 'phi' in self.logs and (self.phi > 1).data.numpy():\n",
    "                            self.phi = Variable(torch.FloatTensor(np.array([0.9])), requires_grad=True)\n",
    "                        if 'phi' in self.logs and (self.phi < 0).data.numpy():\n",
    "                            self.phi = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "                            \n",
    "                    self.logging()\n",
    "                    \n",
    "                    # Remember last values\n",
    "                    prev_z1 = z1_predict \n",
    "                    prev_z2 = z2_predict\n",
    "\n",
    "                    # Compute next value in z\n",
    "                    if np.random.binomial(n=1, p=prob, size=1) == 0:\n",
    "                        next_z1 = self.theta_1 * predict + (1 - self.theta_1) * (A + B * (n + i + 1))\n",
    "                        next_z2 = self.theta_2 * predict + (1 - self.theta_2) * (A + B * (n + i + 1))\n",
    "                    else:\n",
    "                        next_z1 = self.theta_1 * targets_var[i] + (1 - self.theta_1) * (A + B * (n + i + 1))\n",
    "                        next_z2 = self.theta_2 * targets_var[i] + (1 - self.theta_2) * (A + B * (n + i + 1))\n",
    "\n",
    "                    #Compute next exp mean\n",
    "                    z1_predict = self.method_next(prev_z1, next_z1)\n",
    "                    z2_predict = self.method_next(prev_z2, next_z2)\n",
    "                \n",
    "                \n",
    "                if not self.is_sgd:\n",
    "                    opt.zero_grad()\n",
    "                    loss = loss_function(full_predict, targets_var)\n",
    "                    self.logs['err_log'].append(loss.data.numpy()[0])\n",
    "                    self.logs['mean_err_log'].append(loss.data.numpy()[0])\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    opt.step()\n",
    "                \n",
    "                #decrease prob\n",
    "                prob = self.schedule(prob, i)\n",
    "#                 print(prob)\n",
    "                if self.is_sgd:\n",
    "                    self.logs['mean_err_log'].append(np.mean(self.logs['err_log'][-self.test_size : ]))\n",
    "\n",
    "            else:\n",
    "                predicts = Variable(torch.FloatTensor(np.zeros(len(targets_var))))            \n",
    "                z1_predict = self.method(z_var_1)\n",
    "                z2_predict = self.method(z_var_2)\n",
    "\n",
    "                predicts[0] = self.get_predict(z1_predict, z2_predict)\n",
    "                \n",
    "                h = Variable(torch.FloatTensor(np.arange(1, len(targets_var))))\n",
    "#                 if it % 200 == 0:\n",
    "#                     print(\"z1_predict\", z1_predict, \"h\", h)\n",
    "#                     print(\"next_iter\", self.method_next(z1_predict, h = h))\n",
    "                z1_predict = self.method_next(z1_predict, h = h)\n",
    "                z2_predict = self.method_next(z2_predict, h = h)\n",
    "                predicts[1:] = self.get_predict(z1_predict, z2_predict)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss = loss_function(targets_var, predicts)\n",
    "                self.logs['err_log'].append(loss.data.numpy()[0])\n",
    "                self.logs['mean_err_log'].append(loss.data.numpy()[0])\n",
    "                loss.backward(retain_graph=True)\n",
    "                opt.step()\n",
    "                \n",
    "                if constraints_1:\n",
    "                    if (self.theta_1 < 0).data.numpy():\n",
    "                        self.theta_1 = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "                    if (self.theta_1 > 1).data.numpy():\n",
    "                        self.theta_1 = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "                    if (self.theta_2 < 1).data.numpy():\n",
    "                        self.theta_2 = Variable(torch.FloatTensor(np.array([1.5])), requires_grad=True)\n",
    "                \n",
    "                if constraints_2:\n",
    "                    if (self.alpha > 1).data.numpy():\n",
    "                        self.alpha = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "                    if (self.alpha < 0).data.numpy():\n",
    "                        self.alpha = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "                        \n",
    "                    if 'beta' in self.logs and (self.beta > 1).data.numpy():\n",
    "                        self.beta = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "                    if 'beta' in self.logs and (self.beta < 0).data.numpy():\n",
    "                        self.beta = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "                        \n",
    "                    if 'phi' in self.logs and (self.phi > 1).data.numpy():\n",
    "                        self.phi = Variable(torch.FloatTensor(np.array([0.9])), requires_grad=True)\n",
    "                    if 'phi' in self.logs and (self.phi < 0).data.numpy():\n",
    "                        self.phi = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "            \n",
    "                self.logging()\n",
    "                \n",
    "#             if it % self.verbose == 0 or it == n_iters - 1:\n",
    "#                 self.print_graph()\n",
    "                    \n",
    "        return self.logs['err_log']\n",
    "                \n",
    "    def predict(self, data_base, n_iters, use_h = None):\n",
    "        '''\n",
    "        Predict n_iters values\n",
    "        n_iters - number of values to predict\n",
    "        use_h - use h for prediction or predict iteratively\n",
    "        '''\n",
    "        \n",
    "        if use_h is None:\n",
    "            use_h = self.use_h\n",
    "        \n",
    "        y_np = np.copy(data_base)\n",
    "        n = len(y_np)\n",
    "\n",
    "        t_np = np.arange(n) + 1\n",
    "        t_var = Variable(torch.FloatTensor(t_np))\n",
    "        y_var = Variable(torch.FloatTensor(y_np))\n",
    "\n",
    "        B = 6 / (n ** 2 - 1) * (2 / n * np.sum(t_np * y_np) - (1 + n) / n * np.sum(y_np))\n",
    "        A = 1 / n * np.sum(y_np) - (n + 1) / 2 * B\n",
    "\n",
    "        B = Variable(torch.FloatTensor(np.array([B])))\n",
    "        A = Variable(torch.FloatTensor(np.array([A])))\n",
    "\n",
    "        z_var_1 = self.theta_1 * y_var + (1 - self.theta_1) * (A + B * t_var)\n",
    "        z_var_2 = self.theta_2 * y_var + (1 - self.theta_2) * (A + B * t_var)\n",
    "\n",
    "        z1_predict = self.method(z_var_1)\n",
    "        z2_predict = self.method(z_var_2)\n",
    "\n",
    "        predicted_values = []\n",
    "\n",
    "        \n",
    "        if self.using_method == 'exp_mean' or not use_h:\n",
    "#             for i in tqdm(range(n_iters)):\n",
    "            for i in range(n_iters):\n",
    "                predict = self.get_predict(z1_predict, z2_predict)\n",
    "            \n",
    "#                 print(z1_predict, z2_predict, predict)\n",
    "                predicted_values.append(predict.data.numpy()[0])\n",
    "                # Remember last values\n",
    "                prev_z1 = z1_predict \n",
    "                prev_z2 = z2_predict\n",
    "\n",
    "                # Compute next value in z\n",
    "\n",
    "                next_z1 = self.theta_1 * predict + (1 - self.theta_1) * (A + B * (n + i + 1))\n",
    "                next_z2 = self.theta_2 * predict + (1 - self.theta_2) * (A + B * (n + i + 1))\n",
    "\n",
    "                #Compute next exp mean\n",
    "                z1_predict = self.method_next(prev_z1, next_z1)\n",
    "                z2_predict = self.method_next(prev_z2, next_z2)\n",
    "\n",
    "            return np.array(predicted_values)\n",
    "        \n",
    "        else:\n",
    "            #print('Here')\n",
    "            predicts = np.zeros(n_iters)\n",
    "            z1_predict = self.method(z_var_1)\n",
    "            z2_predict = self.method(z_var_2)\n",
    "            predicts[0] = self.get_predict(z1_predict, z2_predict).data.numpy()\n",
    "            \n",
    "            h = Variable(torch.FloatTensor(np.arange(1, n_iters)))\n",
    "            #print(h)\n",
    "            z1_predict = self.method_next(z1_predict, h = h)\n",
    "            #print(z1_predict)\n",
    "            z2_predict = self.method_next(z2_predict, h = h)\n",
    "            #print(z2_predict)\n",
    "            predicts[1:] = self.get_predict(z1_predict, z2_predict).data.numpy()\n",
    "            \n",
    "            return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 24 23\n"
     ]
    }
   ],
   "source": [
    "# train1,train2 --- длины не менее 2\n",
    "series = np.asarray(dfq[84])\n",
    "test = np.split(series, [-horq])[1].copy()\n",
    "train = np.split(series, [-horq])[0].copy() \n",
    "try:\n",
    "    train1,train2 = np.split(train, 2)\n",
    "except ValueError:\n",
    "    train1 = np.split(train, [len(train)//2+1])[0].copy()\n",
    "    train2 = np.split(train, [len(train)//2+1])[1].copy() ## ругается на длину 1 \n",
    "#train1 = np.array([1,2])\n",
    "#train2 = np.array([2,3])\n",
    "print(len(test),len(train1),len(train2))\n",
    "# use SES method with constraints\n",
    "model = VSModel(verbose=1000,method='holts', lr=0.0015,use_h=False, is_sgd=False)\n",
    "logs = model.fit(train1, train2, n_iters = 1000, constraints_1=True)\n",
    "predict = model.predict(train, horq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44.03150177  57.29329681  61.00098419]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 49.077,  54.76 ,  63.482])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1942/1942 [3:38:37<00:00,  6.75s/it]\n"
     ]
    }
   ],
   "source": [
    "#constraints_1=True\n",
    "preds = list()\n",
    "tests = list()\n",
    "trains = list()\n",
    "for i in tqdm(range(len(dfq))):\n",
    "    # load and split data\n",
    "    series = np.asarray(dfq[i])\n",
    "    test = np.split(series, [-horq])[1].copy()\n",
    "    train = np.split(series, [-horq])[0].copy() \n",
    "    tests.append(test)\n",
    "    trains.append(train)\n",
    "    try:\n",
    "        train1,train2 = np.split(train, 2)\n",
    "    except ValueError:\n",
    "        train1 = np.split(train, [len(train)//2+1])[0].copy()\n",
    "        train2 = np.split(train, [len(train)//2+1])[1].copy()\n",
    "\n",
    "    # use SES method with constraints\n",
    "    model = VSModel(verbose=1000,method='exp_trend',lr=0.0015, is_sgd=False,use_h=True)\n",
    "    logs = model.fit(train1, train2, n_iters = 1000,constraints_1=True)\n",
    "    predict = model.predict(train, horq)\n",
    "    preds.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = list()\n",
    "\n",
    "# for i in tqdm(range(len(dfq))):\n",
    "#     # load and split data\n",
    "#     series = np.asarray(dfq[i])\n",
    "#     test = np.split(series, [-horq])[1].copy()\n",
    "#     train = np.split(series, [-horq])[0].copy() \n",
    "#     train1 = np.split(train, [len(train)//2+1])[0].copy()\n",
    "#     train2 = np.split(train, [len(train)//2+1])[1].copy()\n",
    "\n",
    "#     # use SES method with constraints\n",
    "#     model = VSModel(verbose=1000)\n",
    "#     logs = model.fit(train1, train2, n_iters = 1000,constraints=False)\n",
    "#     predict = model.predict(train, horq)\n",
    "#     preds.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.28821683,  1.35035658,  1.34963918], dtype=float32),\n",
       " array([ 64.02655792,  67.63368988,  67.95970917], dtype=float32),\n",
       " array([ 2.40820742,  2.42398882,  2.48016906], dtype=float32),\n",
       " array([  9.54394817,   9.86805534,  10.00674248], dtype=float32),\n",
       " array([ 5675.1640625 ,  5512.72949219,  5714.86181641], dtype=float32)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = 'yearexptrend_useh_preds.csv'\n",
    "#Assuming res is a list of lists\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerows(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvfile = 'yearexptrend_useh_tests.csv'\n",
    "#Assuming res is a list of lists\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerows(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvfile = 'yearexptrend_useh_trains.csv'\n",
    "#Assuming res is a list of lists\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerows(trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = 'quarter_exp_mean_noconstr_preds.csv'\n",
    "#Assuming res is a list of lists\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerows(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = list()\n",
    "\n",
    "for i in range(len(dfm)):\n",
    "    # load and split data\n",
    "    series = np.asarray(dfm[i])\n",
    "    test = np.split(series, [-horm])[1].copy()\n",
    "    train = np.split(series, [-horm])[0].copy() \n",
    "    train1 = np.split(train, [len(train)//2+1])[0].copy()\n",
    "    train2 = np.split(train, [len(train)//2+1])[1].copy()\n",
    "\n",
    "    # use SES method with constraints\n",
    "    model = VSModel(verbose=1000, method='holts')\n",
    "    logs = model.fit(train1, train2, n_iters = 1000,constraints=True)\n",
    "    predict = model.predict(train, horm)\n",
    "    preds.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvfile = 'month_exp_mean_constr_preds.csv'\n",
    "#Assuming res is a list of lists\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerows(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VSModel(verbose=1000)\n",
    "model.theta_1 = Variable(torch.FloatTensor(np.array([0])), requires_grad=True)\n",
    "model.theta_2 = Variable(torch.FloatTensor(np.array([2.0])), requires_grad=True)\n",
    "model.alpha = Variable(torch.FloatTensor(np.array([0.5])), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_predict(self, em1, em2):\n",
    "    '''Compute predicted value, formulas required, that 0 < theta_1 < 1, theta_2 > 1'''\n",
    "\n",
    "    w1 = (self.theta_2 - 1) / (self.theta_2 - self.theta_1)\n",
    "    w2 = (1 - self.theta_1) / (self.theta_2 - self.theta_1)\n",
    "\n",
    "    return w1 * em1 + w2 * em2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Variable containing:\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 2837.1018\n",
      " 2847.3557\n",
      " 2857.6099\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 2758.5586\n",
      " 2760.7402\n",
      " 2762.9216\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(train, horq, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2791.94775391,  2791.94873047,  2791.94873047,  2791.94873047], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2826.84765625,  2797.83007812,  2794.51342773,  2797.77978516], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2826.84765625,  2797.83007812,  2804.04785156,  2810.265625  ])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2855.472,  2922.264,  2976.629,  3049.011])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2790.9479999999999"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 10\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Variable(torch.arange(11))\n",
    "model.alpha = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True) \n",
    "model.exp_mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.96547581,  3.18818972,  3.94633887,  5.23008392])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(predict - test) / test * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Черновик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_mean(z):\n",
    "    exp = Variable(torch.arange(z.shape[0]))\n",
    "    exp.requires_grad = False\n",
    "    \n",
    "    power = torch.pow(1-alpha, exp)\n",
    "    return torch.sum(alpha * power * z)\n",
    "\n",
    "def get_predict(em1, em2):\n",
    "    return(theta_2 - 1) / (theta_2 - theta_1) * em1 + (1 - theta_1) / (theta_2 - theta_1) * em2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init Thetas\n",
    "\n",
    "theta_1 = Variable(torch.FloatTensor(np.array([0.0])))\n",
    "theta_2 = Variable(torch.FloatTensor(np.array([2.0])))\n",
    "theta_1.requires_grad=True\n",
    "theta_2.requires_grad=True\n",
    "\n",
    "# Init alpha\n",
    "\n",
    "alpha = Variable(torch.FloatTensor(np.array([0.1])))\n",
    "alpha.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Init Data\n",
    "\n",
    "y_np = get_data()\n",
    "n = len(y_np)\n",
    "\n",
    "t_np = np.arange(n) + 1\n",
    "t_var = Variable(torch.FloatTensor(t_np))\n",
    "# t_var.requires_grad = False\n",
    "\n",
    "y_var = Variable(torch.FloatTensor(y_np))\n",
    "# y_var.requires_grad = False\n",
    "\n",
    "B = 6 / (n ** 2 - 1) * (2 / n * np.sum(t_np * y_np) - (1 + n) / n * np.sum(y_np))\n",
    "A = 1 / n * np.sum(y_np) - (n + 1) / 2 * B\n",
    "\n",
    "B = Variable(torch.FloatTensor(np.array([B])))\n",
    "A = Variable(torch.FloatTensor(np.array([A])))\n",
    "# B.requires_grad = False\n",
    "# A.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init z\n",
    "z_var_1 = theta_1 * y_var + (1 - theta_1) * (A + B * t_var)\n",
    "z_var_2 = theta_2 * y_var + (1 - theta_2) * (A + B * t_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "n_iters = 100\n",
    "opt = torch.optim.Adam([theta_1, theta_2, alpha])\n",
    "\n",
    "targets_np = get_data()\n",
    "targets_var = Variable(torch.FloatTensor(targets_np))\n",
    "\n",
    "for _ in tqdm(range(n_iters)):\n",
    "#     prev_z1 = exp_mean(z_var_1[:-1])\n",
    "#     prev_z2 = exp_mean(z_var_2[:-1])\n",
    "    \n",
    "#     next_z1 = alpha * z_var_1[-1] + (1 - alpha) * prev_z1\n",
    "#     next_z2 = alpha * z_var_2[-1] + (1 - alpha) * prev_z2\n",
    "    \n",
    "    z1_predict = exp_mean(z_var_1)\n",
    "    z2_predict = exp_mean(z_var_2)\n",
    "    \n",
    "    for i in range(targets_var.shape[0]):\n",
    "        predict = get_predict(z1_predict, z2_predict)\n",
    "        loss = torch.abs(predict - targets_var[i])\n",
    "        \n",
    "#         print(predict)\n",
    "#         print(loss)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        opt.step()\n",
    "        \n",
    "        if (theta_1 < 0).data.numpy():\n",
    "            theta_1 = Variable(torch.FloatTensor(np.array([0.0])), requires_grad=True)\n",
    "        if (theta_1 > 1).data.numpy():\n",
    "            theta_1 = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "        if (theta_2 < 1).data.numpy():\n",
    "            theta_2 = Variable(torch.FloatTensor(np.array([1.0])), requires_grad=True)\n",
    "        \n",
    "        # Remember last values\n",
    "        prev_z1 = z1_predict \n",
    "        prev_z2 = z2_predict\n",
    "\n",
    "        # Compute next value in z\n",
    "        next_z1 = theta_1 * predict + (1 - theta_1) * (A + B * (n + i + 1))\n",
    "        next_z2 = theta_1 * predict + (1 - theta_2) * (A + B * (n + i + 1))\n",
    "        \n",
    "        #Compute next exp mean\n",
    "        z1_predict = alpha * next_z1 + (1 - alpha) * prev_z1\n",
    "        z2_predict = alpha * next_z2 + (1 - alpha) * prev_z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       "  1.8427\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       "  0.4019\n",
       " [torch.FloatTensor of size 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_1, theta_2, alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
